{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cfd6a48b-a4b8-4d02-91b5-e320b4568f17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232, 256, 28)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from Orientation import orientate_base_images\n",
    "\n",
    "oriented_ref = os.path.join(os.path.expanduser(\"~\"), 'Desktop', 'Radiology Internship 2024', 'python code', 'Registration_Torch_Model_Chiang', 'Training Data','Reoriented Base Images (R_)','R_321_FLAIR<=T2_Flair_Axial_p2_5.nii')\n",
    "resampled_attempt = os.path.join(os.path.expanduser(\"~\"), 'Desktop', 'Radiology Internship 2024', 'python code', 'Registration_Torch_Model_Chiang', 'Training Data','Resampled Images','R_321_FLAIR<=T2_Flair_Axial_p2_5.nii')\n",
    "base = os.path.join(os.path.expanduser(\"~\"), 'Desktop', 'Radiology Internship 2024', 'python code', 'Registration_Torch_Model_Chiang', 'Training Data','Base Images','321_FLAIR<=T2_Flair_Axial_p2_5.nii')\n",
    "ref = os.path.join(os.path.expanduser(\"~\"), 'Desktop', 'Radiology Internship 2024', 'python code', 'Registration_Torch_Model_Chiang', 'Training Data','Reference Images (w3_)','w3_321_FLAIR<=T2_Flair_Axial_p2_5.nii')\n",
    "\n",
    "\n",
    "oriented_img = nib.load(oriented_ref)\n",
    "resampled_img = nib.load(resampled_attempt)\n",
    "base_img = nib.load(base)\n",
    "ref_img = nib.load(ref)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "base_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "773da496-98f2-454d-b4db-b11594ba87bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-8.59375000e-01  1.76260742e-10 -2.32475313e-16  9.96875000e+01]\n",
      " [ 1.73309242e-10  8.44984710e-01 -1.09341311e+00  3.91958191e+02]\n",
      " [ 3.21209344e-11  1.56608656e-01  5.89952946e+00  1.33387165e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "[[ 2.00000000e+00 -4.10206813e-10  7.73506517e-17 -9.88281250e+01]\n",
      " [-4.03337863e-10 -1.96650982e+00  3.64471048e-01  1.07436035e+02]\n",
      " [-7.47541751e-11 -3.64471048e-01 -1.96650982e+00  1.72626007e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "\n",
      "\n",
      "[[-8.59375000e-01 -1.76260742e-10 -2.32475313e-16  9.96875000e+01]\n",
      " [ 1.73309242e-10 -8.44984710e-01 -1.09341311e+00  1.36958191e+02]\n",
      " [ 3.21209344e-11 -1.56608656e-01  5.89952946e+00  1.33387165e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "affine_oriented = oriented_img.affine\n",
    "affine_resampled = resampled_img.affine\n",
    "affine_base = base_img.affine\n",
    "print(affine_oriented)\n",
    "print(affine_resampled)\n",
    "print('\\n')\n",
    "print(affine_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7086930-fed3-440e-b679-e1389de06d96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.91958191e+02 - 1.36958191e+02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f28597bc-4f1a-4bd8-886b-eb250947610f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b''\n",
      "dim_info        : 0\n",
      "dim             : [  3 232 256  28   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : float64\n",
      "bitpix          : 64\n",
      "slice_start     : 0\n",
      "pixdim          : [-1.        0.859375  0.859375  6.        1.        1.        1.\n",
      "  1.      ]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 0\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : b''\n",
      "aux_file        : b''\n",
      "qform_code      : unknown\n",
      "sform_code      : aligned\n",
      "quatern_b       : -1.0212149e-10\n",
      "quatern_c       : -0.9958049\n",
      "quatern_d       : -0.091501616\n",
      "qoffset_x       : 99.6875\n",
      "qoffset_y       : 391.9582\n",
      "qoffset_z       : 13.3387165\n",
      "srow_x          : [-8.5937500e-01  1.7626074e-10 -2.3247531e-16  9.9687500e+01]\n",
      "srow_y          : [ 1.7330924e-10  8.4498471e-01 -1.0934131e+00  3.9195819e+02]\n",
      "srow_z          : [3.21209344e-11 1.56608656e-01 5.89952946e+00 1.33387165e+01]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n",
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b''\n",
      "dim_info        : 0\n",
      "dim             : [  3 100 111  82   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : float32\n",
      "bitpix          : 32\n",
      "slice_start     : 0\n",
      "pixdim          : [1.       0.859375 0.859375 6.       1.       1.       1.       1.      ]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 0\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : b''\n",
      "aux_file        : b''\n",
      "qform_code      : unknown\n",
      "sform_code      : aligned\n",
      "quatern_b       : 9.383627e-12\n",
      "quatern_c       : -0.091501616\n",
      "quatern_d       : 0.9958049\n",
      "qoffset_x       : 99.6875\n",
      "qoffset_y       : 136.95819\n",
      "qoffset_z       : 13.3387165\n",
      "srow_x          : [-8.5937500e-01 -1.7626074e-10 -2.3247531e-16  9.9687500e+01]\n",
      "srow_y          : [ 1.7330924e-10 -8.4498471e-01 -1.0934131e+00  1.3695819e+02]\n",
      "srow_z          : [ 3.21209344e-11 -1.56608656e-01  5.89952946e+00  1.33387165e+01]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n"
     ]
    }
   ],
   "source": [
    "header_oriented = oriented_img.header\n",
    "header_resampled = resampled_img.header\n",
    "print(header_oriented)\n",
    "print(header_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9a8591a2-6633-4567-a368-11f52d73c433",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.859375 0.859375 6.0\n",
      "0.859375 0.859375 6.0\n",
      "2.0 2.0 2.0\n"
     ]
    }
   ],
   "source": [
    "sx, sy, sz = oriented_img.header.get_zooms()\n",
    "tx, ty, tz = base_img.header.get_zooms()\n",
    "zx, zy, zz = ref_img.header.get_zooms()\n",
    "print(sx,sy,sz)\n",
    "print(tx,ty,tz)\n",
    "print(zx,zy,zz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8225add-1c0a-4ab9-8b32-726e1cb0fa47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from Orientation import orientate_base_images\n",
    "\n",
    "import monai\n",
    "from monai.data import Dataset, DataLoader\n",
    "from monai.transforms import (\n",
    "    LoadImage,\n",
    "    EnsureChannelFirst,\n",
    "    Orientation,\n",
    "    Spacing,\n",
    "    Compose,\n",
    "    SaveImage,\n",
    "    ToTensor,\n",
    ")\n",
    "#help(Compose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bb17e98-48de-48df-9c92-939f9f7e3404",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The orientation of the NIfTI file is: ('L', 'A', 'S')\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "# Load the NIfTI file\n",
    "\n",
    "file_path = '/Users/theochiang/Documents/MATLAB/spm-main/tpm/TPM.nii'\n",
    "nifti_file = nib.load(file_path)\n",
    "\n",
    "# Get the affine matrix\n",
    "affine = nifti_file.affine\n",
    "\n",
    "# Determine the orientation of the NIfTI file\n",
    "orientation = nib.aff2axcodes(affine)\n",
    "\n",
    "# Print the orientation\n",
    "print(f\"The orientation of the NIfTI file is: {orientation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48df577c-8a84-422d-a2bc-b7dd7605b946",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., -1.],\n",
       "       [ 1.,  1.],\n",
       "       [ 2.,  1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = nib.orientations.ornt_transform(\n",
    "            nib.orientations.axcodes2ornt(('R','A','S')),\n",
    "            nib.orientations.axcodes2ornt(('L','A','S'))\n",
    "        )\n",
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d53185d0-0c00-478c-a33f-7cd85a157682",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.327272727272727"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2/.859375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3bf7f75c-ed2a-4d6e-b1f3-f8edcd5af5c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-8.59375000e-01 -1.76260742e-10 -2.32475313e-16  9.96875000e+01]\n",
      " [ 1.73309242e-10 -8.44984710e-01 -1.09341311e+00  1.36958191e+02]\n",
      " [ 3.21209344e-11 -1.56608656e-01  5.89952946e+00  1.33387165e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "\n",
      "\n",
      "[\n",
      "[-8.5937500000e-01 -1.7626074200e-10 -2.3247531300e-16  9.9687500000e+01]\n",
      "[ 1.7330924200e-10 -8.4498471000e-01 -1.0934131100e+00  1.3695819100e+02]\n",
      "[ 3.2120934400e-11 -1.5660865600e-01  5.8995294600e+00  1.3338716500e+01]\n",
      "[ 0.0000000000e+00  0.0000000000e+00  0.0000000000e+00  1.0000000000e+00]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(affine_base)\n",
    "print('\\n')\n",
    "def print_affine_matrix(matrix):\n",
    "    print(\"[\")\n",
    "    for row in matrix:\n",
    "        formatted_row = \" \".join([f\"{item: .10e}\" for item in row])\n",
    "        print(f\"[{formatted_row}]\")\n",
    "    print(\"]\")\n",
    "\n",
    "# Example matrix\n",
    "affine_matrix = np.array([\n",
    "    [-8.59375000e-01, -1.76260742e-10, -2.32475313e-16,  9.96875000e+01],\n",
    " [ 1.73309242e-10, -8.44984710e-01, -1.09341311e+00,  1.36958191e+02],\n",
    " [ 3.21209344e-11, -1.56608656e-01,  5.89952946e+00,  1.33387165e+01],\n",
    " [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00]\n",
    "])\n",
    "\n",
    "# Print the affine matrix using the print function\n",
    "print_affine_matrix(affine_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73aecdfc-bdd6-49c1-8b0e-f719b638cf4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing 384_FLAIR<=AX_FLAIR_5.nii with w3_340_FLAIR<=AX_FLAIR_5.nii:\n",
      "  Same Orientation: No\n",
      "  Same Voxel Spacing: No\n",
      "\n",
      "Comparing 378_FLAIR<=AX_FLAIR_5.nii with w3_384_FLAIR<=AX_FLAIR_5.nii:\n",
      "  Same Orientation: No\n",
      "  Same Voxel Spacing: No\n",
      "\n",
      "Comparing 462_FLAIR<=AX_FLAIR_6.nii with w3_426_FLAIR<=T2_Flair_Axial_p2_8.nii:\n",
      "  Same Orientation: No\n",
      "  Same Voxel Spacing: No\n",
      "\n",
      "Comparing 370_FLAIR<=T2_Flair_Axial_p2_5.nii with w3_462_FLAIR<=AX_FLAIR_6.nii:\n",
      "  Same Orientation: No\n",
      "  Same Voxel Spacing: No\n",
      "\n",
      "Comparing 340_FLAIR<=AX_FLAIR_5.nii with w3_378_FLAIR<=AX_FLAIR_5.nii:\n",
      "  Same Orientation: No\n",
      "  Same Voxel Spacing: No\n",
      "\n",
      "Comparing 358_FLAIR<=AX_FLAIR_5.nii with w3_431_FLAIR<=T2_Flair_Axial_p2_6.nii:\n",
      "  Same Orientation: No\n",
      "  Same Voxel Spacing: No\n",
      "\n",
      "Comparing 458_FLAIR<=T2_Flair_Axial_p2_5.nii with w3_466_FLAIR<=AX_FLAIR_3.nii:\n",
      "  Same Orientation: No\n",
      "  Same Voxel Spacing: No\n",
      "\n",
      "Comparing 390_FLAIR<=T2_Flair_Axial_p2_5.nii with w3_459_FLAIR<=T2_Flair_Axial_p2_8.nii:\n",
      "  Same Orientation: No\n",
      "  Same Voxel Spacing: No\n",
      "\n",
      "Comparing 466_FLAIR<=AX_FLAIR_3.nii with w3_449_FLAIR<=T2_Flair_Axial_p2_5.nii:\n",
      "  Same Orientation: No\n",
      "  Same Voxel Spacing: No\n",
      "\n",
      "Comparing 321_FLAIR<=T2_Flair_Axial_p2_5.nii with w3_358_FLAIR<=AX_FLAIR_5.nii:\n",
      "  Same Orientation: No\n",
      "  Same Voxel Spacing: No\n",
      "\n",
      "Comparing 463_FLAIR<=AX_FLAIR_5.nii with w3_366_FLAIR<=T2_Flair_Axial_p2_5.nii:\n",
      "  Same Orientation: No\n",
      "  Same Voxel Spacing: No\n",
      "\n",
      "Comparing 461_FLAIR<=AX_FLAIR_5.nii with w3_445_FLAIR<=AX_FLAIR_6.nii:\n",
      "  Same Orientation: No\n",
      "  Same Voxel Spacing: No\n",
      "\n",
      "Comparing 426_FLAIR<=T2_Flair_Axial_p2_8.nii with w3_461_FLAIR<=AX_FLAIR_5.nii:\n",
      "  Same Orientation: No\n",
      "  Same Voxel Spacing: No\n",
      "\n",
      "Comparing 445_FLAIR<=AX_FLAIR_6.nii with w3_370_FLAIR<=T2_Flair_Axial_p2_5.nii:\n",
      "  Same Orientation: No\n",
      "  Same Voxel Spacing: No\n",
      "\n",
      "Comparing 467_FLAIR<=AX_FLAIR_5.nii with w3_463_FLAIR<=AX_FLAIR_5.nii:\n",
      "  Same Orientation: No\n",
      "  Same Voxel Spacing: No\n",
      "\n",
      "Comparing 431_FLAIR<=T2_Flair_Axial_p2_6.nii with w3_435_FLAIR<=Ax_TSE_Flair_Blade_8.nii:\n",
      "  Same Orientation: No\n",
      "  Same Voxel Spacing: No\n",
      "\n",
      "Comparing 459_FLAIR<=T2_Flair_Axial_p2_8.nii with w3_415_FLAIR<=AX_FLAIR_5.nii:\n",
      "  Same Orientation: No\n",
      "  Same Voxel Spacing: No\n",
      "\n",
      "Comparing 381_FLAIR<=AX_FLAIR_6.nii with w3_345_FLAIR<=AX_FLAIR_5.nii:\n",
      "  Same Orientation: No\n",
      "  Same Voxel Spacing: No\n",
      "\n",
      "Comparing 435_FLAIR<=Ax_TSE_Flair_Blade_8.nii with w3_467_FLAIR<=AX_FLAIR_5.nii:\n",
      "  Same Orientation: No\n",
      "  Same Voxel Spacing: No\n",
      "\n",
      "Comparing 415_FLAIR<=AX_FLAIR_5.nii with w3_458_FLAIR<=T2_Flair_Axial_p2_5.nii:\n",
      "  Same Orientation: No\n",
      "  Same Voxel Spacing: No\n",
      "\n",
      "Comparing 345_FLAIR<=AX_FLAIR_5.nii with w3_321_FLAIR<=T2_Flair_Axial_p2_5.nii:\n",
      "  Same Orientation: No\n",
      "  Same Voxel Spacing: No\n",
      "\n",
      "Comparing 366_FLAIR<=T2_Flair_Axial_p2_5.nii with w3_381_FLAIR<=AX_FLAIR_6.nii:\n",
      "  Same Orientation: No\n",
      "  Same Voxel Spacing: No\n",
      "\n",
      "Comparing 449_FLAIR<=T2_Flair_Axial_p2_5.nii with w3_390_FLAIR<=T2_Flair_Axial_p2_5.nii:\n",
      "  Same Orientation: No\n",
      "  Same Voxel Spacing: No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "# Suppress the specific deprecation warning\n",
    "warnings.filterwarnings(\"ignore\", message=\".*`torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.*\")\n",
    "\n",
    "# Define paths\n",
    "data_dir = os.path.join(os.path.expanduser(\"~\"), 'Desktop', 'Radiology Internship 2024', 'python code', 'Registration_Torch_Model_Chiang', 'Training Data')\n",
    "base_image_paths = [os.path.join(data_dir, 'Base Images', f) for f in os.listdir(os.path.join(data_dir, 'Base Images')) if f.endswith(('.nii', '.nii.gz'))]\n",
    "reference_image_paths = [os.path.join(data_dir, 'Reference Images (w3_)', f) for f in os.listdir(os.path.join(data_dir, 'Reference Images (w3_)')) if f.endswith(('.nii', '.nii.gz'))]\n",
    "\n",
    "def check_orientation_and_spacing(base_image_path, reference_image_path):\n",
    "    base_img = nib.load(base_image_path)\n",
    "    ref_img = nib.load(reference_image_path)\n",
    "    \n",
    "    # Check orientation\n",
    "    base_orientation = nib.aff2axcodes(base_img.affine)\n",
    "    ref_orientation = nib.aff2axcodes(ref_img.affine)\n",
    "    \n",
    "    # Check voxel spacing\n",
    "    base_spacing = np.sqrt(np.sum(base_img.affine[:3, :3] ** 2, axis=0))\n",
    "    ref_spacing = np.sqrt(np.sum(ref_img.affine[:3, :3] ** 2, axis=0))\n",
    "    \n",
    "    same_orientation = base_orientation == ref_orientation\n",
    "    same_spacing = np.allclose(base_spacing, ref_spacing)\n",
    "    \n",
    "    return same_orientation, same_spacing\n",
    "\n",
    "# Iterate over the base and reference images to compare their orientation and spacing\n",
    "for base_image_path, reference_image_path in zip(base_image_paths, reference_image_paths):\n",
    "    same_orientation, same_spacing = check_orientation_and_spacing(base_image_path, reference_image_path)\n",
    "    \n",
    "    print(f\"Comparing {os.path.basename(base_image_path)} with {os.path.basename(reference_image_path)}:\")\n",
    "    print(f\"  Same Orientation: {'Yes' if same_orientation else 'No'}\")\n",
    "    print(f\"  Same Voxel Spacing: {'Yes' if same_spacing else 'No'}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0b4db118-f912-45a6-9bbb-09aeb4b21f7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Orientation: LAS\n",
      "Target Spacing: [2. 2. 2.]\n",
      "og Spacing: [0.859375   0.85937503 6.00000028]\n",
      "Loading image: /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Base Images/384_FLAIR<=AX_FLAIR_5.nii\n",
      "Loaded image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Transformed image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Saved resampled image to /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Resampled Images/R_384_FLAIR<=AX_FLAIR_5.nii\n",
      "Loading image: /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Base Images/378_FLAIR<=AX_FLAIR_5.nii\n",
      "Loaded image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Transformed image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Saved resampled image to /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Resampled Images/R_378_FLAIR<=AX_FLAIR_5.nii\n",
      "Loading image: /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Base Images/462_FLAIR<=AX_FLAIR_6.nii\n",
      "Loaded image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Transformed image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Saved resampled image to /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Resampled Images/R_462_FLAIR<=AX_FLAIR_6.nii\n",
      "Loading image: /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Base Images/370_FLAIR<=T2_Flair_Axial_p2_5.nii\n",
      "Loaded image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Transformed image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Saved resampled image to /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Resampled Images/R_370_FLAIR<=T2_Flair_Axial_p2_5.nii\n",
      "Loading image: /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Base Images/340_FLAIR<=AX_FLAIR_5.nii\n",
      "Loaded image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Transformed image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Saved resampled image to /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Resampled Images/R_340_FLAIR<=AX_FLAIR_5.nii\n",
      "Loading image: /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Base Images/358_FLAIR<=AX_FLAIR_5.nii\n",
      "Loaded image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Transformed image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Saved resampled image to /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Resampled Images/R_358_FLAIR<=AX_FLAIR_5.nii\n",
      "Loading image: /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Base Images/458_FLAIR<=T2_Flair_Axial_p2_5.nii\n",
      "Loaded image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Transformed image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Saved resampled image to /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Resampled Images/R_458_FLAIR<=T2_Flair_Axial_p2_5.nii\n",
      "Loading image: /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Base Images/390_FLAIR<=T2_Flair_Axial_p2_5.nii\n",
      "Loaded image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Transformed image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Saved resampled image to /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Resampled Images/R_390_FLAIR<=T2_Flair_Axial_p2_5.nii\n",
      "Loading image: /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Base Images/466_FLAIR<=AX_FLAIR_3.nii\n",
      "Loaded image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Transformed image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Saved resampled image to /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Resampled Images/R_466_FLAIR<=AX_FLAIR_3.nii\n",
      "Loading image: /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Base Images/321_FLAIR<=T2_Flair_Axial_p2_5.nii\n",
      "Loaded image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Transformed image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Saved resampled image to /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Resampled Images/R_321_FLAIR<=T2_Flair_Axial_p2_5.nii\n",
      "Loading image: /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Base Images/463_FLAIR<=AX_FLAIR_5.nii\n",
      "Loaded image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Transformed image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Saved resampled image to /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Resampled Images/R_463_FLAIR<=AX_FLAIR_5.nii\n",
      "Loading image: /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Base Images/461_FLAIR<=AX_FLAIR_5.nii\n",
      "Loaded image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Transformed image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Saved resampled image to /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Resampled Images/R_461_FLAIR<=AX_FLAIR_5.nii\n",
      "Loading image: /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Base Images/426_FLAIR<=T2_Flair_Axial_p2_8.nii\n",
      "Loaded image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Transformed image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Saved resampled image to /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Resampled Images/R_426_FLAIR<=T2_Flair_Axial_p2_8.nii\n",
      "Loading image: /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Base Images/445_FLAIR<=AX_FLAIR_6.nii\n",
      "Loaded image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Transformed image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Saved resampled image to /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Resampled Images/R_445_FLAIR<=AX_FLAIR_6.nii\n",
      "Loading image: /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Base Images/467_FLAIR<=AX_FLAIR_5.nii\n",
      "Loaded image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Transformed image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Saved resampled image to /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Resampled Images/R_467_FLAIR<=AX_FLAIR_5.nii\n",
      "Loading image: /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Base Images/431_FLAIR<=T2_Flair_Axial_p2_6.nii\n",
      "Loaded image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Transformed image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Saved resampled image to /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Resampled Images/R_431_FLAIR<=T2_Flair_Axial_p2_6.nii\n",
      "Loading image: /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Base Images/459_FLAIR<=T2_Flair_Axial_p2_8.nii\n",
      "Loaded image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Transformed image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Saved resampled image to /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Resampled Images/R_459_FLAIR<=T2_Flair_Axial_p2_8.nii\n",
      "Loading image: /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Base Images/381_FLAIR<=AX_FLAIR_6.nii\n",
      "Loaded image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Transformed image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Saved resampled image to /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Resampled Images/R_381_FLAIR<=AX_FLAIR_6.nii\n",
      "Loading image: /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Base Images/435_FLAIR<=Ax_TSE_Flair_Blade_8.nii\n",
      "Loaded image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Transformed image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Saved resampled image to /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Resampled Images/R_435_FLAIR<=Ax_TSE_Flair_Blade_8.nii\n",
      "Loading image: /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Base Images/415_FLAIR<=AX_FLAIR_5.nii\n",
      "Loaded image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Transformed image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Saved resampled image to /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Resampled Images/R_415_FLAIR<=AX_FLAIR_5.nii\n",
      "Loading image: /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Base Images/345_FLAIR<=AX_FLAIR_5.nii\n",
      "Loaded image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Transformed image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Saved resampled image to /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Resampled Images/R_345_FLAIR<=AX_FLAIR_5.nii\n",
      "Loading image: /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Base Images/366_FLAIR<=T2_Flair_Axial_p2_5.nii\n",
      "Loaded image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Transformed image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Saved resampled image to /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Resampled Images/R_366_FLAIR<=T2_Flair_Axial_p2_5.nii\n",
      "Loading image: /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Base Images/449_FLAIR<=T2_Flair_Axial_p2_5.nii\n",
      "Loaded image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Transformed image: <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Saved resampled image to /Users/theochiang/Desktop/Radiology Internship 2024/python code/Registration_Torch_Model_Chiang/Training Data/Resampled Images/R_449_FLAIR<=T2_Flair_Axial_p2_5.nii\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "#from nonfunctional-Orientation import orientate_base_images\n",
    "\n",
    "import monai\n",
    "from monai.data import Dataset, DataLoader\n",
    "from monai.transforms import (\n",
    "    LoadImage,\n",
    "    EnsureChannelFirst,\n",
    "    Orientation,\n",
    "    Spacing,\n",
    "    Compose,\n",
    "    SaveImage,\n",
    "    ToTensor,\n",
    ")\n",
    "\n",
    "# Suppress the specific deprecation warning\n",
    "warnings.filterwarnings(\"ignore\", message=\".*`torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.*\")\n",
    "\n",
    "\n",
    "# Define paths\n",
    "data_dir = os.path.join(os.path.expanduser(\"~\"), 'Desktop', 'Radiology Internship 2024', 'python code', 'Registration_Torch_Model_Chiang', 'Training Data')\n",
    "base_image_paths = [os.path.join(data_dir, 'Base Images', f) for f in os.listdir(os.path.join(data_dir, 'Base Images')) if f.endswith(('.nii', '.nii.gz'))]\n",
    "\n",
    "reference_image_paths = [os.path.join(data_dir, 'Reference Images (w3_)', f) for f in os.listdir(os.path.join(data_dir, 'Reference Images (w3_)')) if f.endswith(('.nii', '.nii.gz'))]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#FUNCTIONS:\n",
    "\n",
    "def print_transforms(transformations):\n",
    "    print(\"Contents of the Compose object:\")\n",
    "    for i, transform in enumerate(transformations.transforms):\n",
    "        print(f\"Transform {i + 1}: {transform}\")\n",
    "\n",
    "def update_affine(og_affine, transforms, base_spacing):\n",
    "    #ASSUMES REORIENTATION AND VOXEL CHANGE\n",
    "    spacing_transform = transforms.transforms[2]\n",
    "    new_spacing = spacing_transform.pixdim\n",
    "    base_spacing = base_spacing\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def find_target_spacing(reference_image_paths):\n",
    "    nifti_file = nib.load(reference_image_paths[0])\n",
    "    affine = nifti_file.affine\n",
    "    voxel_sizes = np.sqrt(np.sum(affine[:3, :3] ** 2, axis=0))\n",
    "    return(voxel_sizes)\n",
    "\n",
    "def original_spacing(base_image_paths):\n",
    "    nifti_file = nib.load(base_image_paths[0])\n",
    "    affine = nifti_file.affine\n",
    "    voxel_sizes = np.sqrt(np.sum(affine[:3, :3] ** 2, axis=0))\n",
    "    return(voxel_sizes)\n",
    "\n",
    "def find_target_orientation(reference_image_paths):\n",
    "    nifti_file = nib.load(reference_image_paths[0])\n",
    "    affine = nifti_file.affine\n",
    "    target_orientation = nib.aff2axcodes(affine)\n",
    "    return(target_orientation)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Class for dataloader\n",
    "class MedicalImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        print(f\"Loading image: {image_path}\")  # Debug print to check the image path\n",
    "        try:\n",
    "            image = LoadImage(image_only=False)(image_path)\n",
    "            image, metadata = image[0], image[1]\n",
    "\n",
    "            print(f\"Loaded image: {type(image)}\")  # Debug print to check the loaded image type\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "                print(f\"Transformed image: {type(image)}\")  # Debug print to check the transformed image type\n",
    "\n",
    "\n",
    "\n",
    "            #print()\n",
    "\n",
    "            #metadata[1]['affine'] = update_affine(metadata[1]['affine'], transforms, base_spacing)\n",
    "            file_name = os.path.basename(image_path)\n",
    "            return image, file_name, metadata  # Return both the transformed image and the original file name\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")\n",
    "            raise    \n",
    "\n",
    "                \n",
    "#MAIN CLASS\n",
    "def resample(data_dir, base_image_paths, reference_image_paths):\n",
    "    \n",
    "    \n",
    "    # Define the target spacing for resampling (e.g., 1.0mm x 1.0mm x 1.0mm)\n",
    "    \n",
    "    #DONT NEED TO FIND FOR EACH INDIVIDUAL IMAGE CAUSE IS THE SAME\n",
    "    target_spacing = find_target_spacing(reference_image_paths)\n",
    "    target_orientation = find_target_orientation(reference_image_paths)\n",
    "    target_orientation = ''.join(target_orientation)\n",
    "    base_spacing = original_spacing(base_image_paths)\n",
    "    print(\"Target Orientation: \" + str(target_orientation))\n",
    "    print(\"Target Spacing: \" + str(target_spacing))\n",
    "    print(\"og Spacing: \" + str(base_spacing))\n",
    "    #print(\"Voxel spacing: \" + str(target_spacing))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # Define transforms\n",
    "    transforms = Compose([\n",
    "        #LoadImage(image_only=True),\n",
    "        EnsureChannelFirst(),  # Ensures the channel dimension is first\n",
    "        Orientation(axcodes=target_orientation),  # Reorient to RAS\n",
    "        Spacing(pixdim=target_spacing, mode='bilinear'),  # Resample to target spacing\n",
    "        ToTensor()\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "    dataset = MedicalImageDataset(base_image_paths, transform=transforms)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #REORIENT AND RESAMPLE\n",
    "    resampled_dir = os.path.join(data_dir, 'Resampled Images')\n",
    "    os.makedirs(resampled_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    for i, (resampled_image, file_name,metadata) in enumerate(dataloader):\n",
    "        resampled_image = resampled_image.squeeze().numpy()  # Remove batch dimension and convert to numpy array\n",
    "        resampled_image_name = \"R_\" + str(file_name[0])\n",
    "        resampled_image_path = os.path.join(resampled_dir, resampled_image_name)\n",
    "\n",
    "        new_affine = metadata['affine'].squeeze().numpy()\n",
    "\n",
    "\n",
    "        try:\n",
    "            # Create a NIfTI image\n",
    "            nifti_image = nib.Nifti1Image(resampled_image, new_affine)\n",
    "\n",
    "            # Save the NIfTI image\n",
    "            nib.save(nifti_image, resampled_image_path)\n",
    "            print(f\"Saved resampled image to {resampled_image_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving image {resampled_image_path}: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#call from main\n",
    "resample(data_dir, base_image_paths, reference_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c846fd10-be11-4663-af98-7f9f3042e4f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L\n",
      "A\n",
      "S\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'L'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len('LAS')):\n",
    "    print('LAS'[i])\n",
    "    \n",
    "    \n",
    "'LAS'[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6558a715-08e8-45da-8ff8-9b922951abce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = base_image_paths[1]\n",
    "image = nib.load(image_path)\n",
    "image_dims = image.shape\n",
    "image.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e9e78c40-ae9a-466d-a882-e14fe1d39aa3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function crop_indices in module ants.ops.crop_image:\n",
      "\n",
      "crop_indices(image, lowerind, upperind)\n",
      "    Create a proper ANTsImage sub-image by indexing the image with indices. \n",
      "    This is similar to but different from array sub-setting in that \n",
      "    the resulting sub-image can be decropped back into its place without \n",
      "    having to store its original index locations explicitly.\n",
      "    \n",
      "    ANTsR function: `cropIndices`\n",
      "    \n",
      "    Arguments\n",
      "    ---------\n",
      "    image : ANTsImage  \n",
      "        image to crop\n",
      "    \n",
      "    lowerind : list/tuple of integers  \n",
      "        vector of lower index, should be length image dimensionality\n",
      "    \n",
      "    upperind : list/tuple of integers\n",
      "        vector of upper index, should be length image dimensionality\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    ANTsImage\n",
      "    \n",
      "    Example\n",
      "    -------\n",
      "    >>> import ants\n",
      "    >>> fi = ants.image_read( ants.get_ants_data(\"r16\"))\n",
      "    >>> cropped = ants.crop_indices( fi, (10,10), (100,100) )\n",
      "    >>> cropped = ants.smooth_image( cropped, 5 )\n",
      "    >>> decropped = ants.decrop_image( cropped, fi )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ants\n",
    "help(ants.crop_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6ee12a0a-b33a-469f-9bd8-7230b9ec0d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'384_FLAIR<=AX_FLAIR_5.nii'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_image_paths = [os.path.join(data_dir, 'Base Images', f) for f in os.listdir(os.path.join(data_dir, 'Base Images')) if f.endswith(('.nii', '.nii.gz'))]\n",
    "os.path.basename(base_image_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "08403fef-2376-4e9d-a279-97b97818faba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"int\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m],[\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m]]\n\u001b[0;32m----> 2\u001b[0m a \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m10\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"int\") to list"
     ]
    }
   ],
   "source": [
    "a = [[2,3],[5,6]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282259a3-dd69-428b-97e8-26e235dd93e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cec2cc9-24d5-4334-b1af-39dea9546946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
